1. Kafka producer

Flow.

Producer -> Serializer -> Partitioner

Kafka producer can send messages in 3 ways

KafkaProducer<String, Integer> producer = new KafkaProducer<String, Integer>(props);
        ProducerRecord<String, Integer> record = new ProducerRecord<>("OrderTopic", "Mac Book Pro", 10);

a.

        try {
            producer.send(record);
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            producer.close();
        }

Here it is kind of fire and forget. You have sent the message, we do not care about success/failure.

b.
try {
    RecordMetadata recordMetadata = producer.send(record);
    System.out.println(recordMetadata.partition());
    System.out.println(recordMetadata.offset());
    System.out.println("Message Sent Successfully");
} catch (Exception e) {
    e.printStackTrace();
} finally {
    producer.close();
}

It is a blocking call, you wait for the metadata to populate.

c.
We make it async by using a callback

        try {
            producer.send(record,new OrderCallback());
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            producer.close();
        }

        import org.apache.kafka.clients.producer.Callback;
        import org.apache.kafka.clients.producer.RecordMetadata;

        public class OrderCallback implements Callback {
            @Override
            public void onCompletion(RecordMetadata recordMetadata, Exception e) {
                System.out.println(recordMetadata.partition());
                System.out.println(recordMetadata.offset());
                System.out.println("Message Sent Successfully");
                if(e!=null) {
                    e.printStackTrace();
                }
            }
        }


===================
Custom Partitioner
===================

kafka_fundamentals git:(master) kafka-topics --delete --bootstrap-server localhost:9092 --topic OrderPartitionedTopic
➜  kafka_fundamentals git:(master) kafka-topics --list --bootstrap-server localhost:9092
OrderTopic
__consumer_offsets
➜  kafka_fundamentals git:(master) kafka-topics --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 10 --topic OrderPartitionedTopic
Created topic OrderPartitionedTopic.
➜  kafka_fundamentals git:(master) kafka-topics --describe --bootstrap-server localhost:9092 --topic OrderPartitionedTopic
Topic: OrderPartitionedTopic	TopicId: n9aJZCHvTfeC8qf2SyXqeg	PartitionCount: 10	ReplicationFactor: 1	Configs:
	Topic: OrderPartitionedTopic	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
	Topic: OrderPartitionedTopic	Partition: 1	Leader: 0	Replicas: 0	Isr: 0
	Topic: OrderPartitionedTopic	Partition: 2	Leader: 0	Replicas: 0	Isr: 0
	Topic: OrderPartitionedTopic	Partition: 3	Leader: 0	Replicas: 0	Isr: 0
	Topic: OrderPartitionedTopic	Partition: 4	Leader: 0	Replicas: 0	Isr: 0
	Topic: OrderPartitionedTopic	Partition: 5	Leader: 0	Replicas: 0	Isr: 0
	Topic: OrderPartitionedTopic	Partition: 6	Leader: 0	Replicas: 0	Isr: 0
	Topic: OrderPartitionedTopic	Partition: 7	Leader: 0	Replicas: 0	Isr: 0
	Topic: OrderPartitionedTopic	Partition: 8	Leader: 0	Replicas: 0	Isr: 0
	Topic: OrderPartitionedTopic	Partition: 9	Leader: 0	Replicas: 0	Isr: 0


================================
ProducerConfig.ACKS_CONFIG
================================
0   -> producer does not care about acknowledgment.
1   -> broker will send the acknowledgment msg only if leader replica receives the msg.
All -> broker will send the acknowledgment msg only if all the replicas receives the msg.
       So latency is increased.

==================================
ProducerConfig.BUFFER_MEMORY_CONFIG
==================================
props.setProperty(ProducerConfig.BUFFER_MEMORY_CONFIG,
                "35343");

this is the buffer memory that producer will use to buffer
msgs before they are sent to broker.

default values is 256 MB

======================================
ProducerConfig.COMPRESSION_TYPE_CONFIG
======================================

props.setProperty(ProducerConfig.COMPRESSION_TYPE_CONFIG,
                "snappy/lz4/gzip");

by default, msgs are not compressed.

snappy -> google algo for compression, uses less CPU.
gzip -> more compressed files.

======================================
ProducerConfig.RETRIES_CONFIG
======================================

props.setProperty(ProducerConfig.RETRIES_CONFIG,
                "snappy/lz4/gzip");

by default, wait for 100 ms before retry.

======================================
ProducerConfig.BATCH_SIZE_CONFIG
======================================

props.setProperty(ProducerConfig.BATCH_SIZE_CONFIG,
                "34343423");

memory size of the batch in bytes.

======================================
ProducerConfig.LINGER_MS_CONFIG
======================================

props.setProperty(ProducerConfig.LINGER_MS_CONFIG,
                "200");

complements BATCH_SIZE_CONFIG
waits for 200 ms before the batch is handed to main
thread to send to kafka broker

======================================
ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG
======================================

props.setProperty(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG,
                "200");

time for which producer will wait for acknowledgment
after which it will timeout.



================
kafka streams
================

describe topology

Topologies:
   Sub-topology: 0
    Source: KSTREAM-SOURCE-0000000000 (topics: [streams-dataflow-input])
      --> KSTREAM-FILTER-0000000002, KSTREAM-FOREACH-0000000001
    Processor: KSTREAM-FILTER-0000000002 (stores: [])
      --> KSTREAM-MAP-0000000003
      <-- KSTREAM-SOURCE-0000000000
    Processor: KSTREAM-MAP-0000000003 (stores: [])
      --> KSTREAM-SINK-0000000004
      <-- KSTREAM-FILTER-0000000002
    Processor: KSTREAM-FOREACH-0000000001 (stores: [])
      --> none
      <-- KSTREAM-SOURCE-0000000000
    Sink: KSTREAM-SINK-0000000004 (topic: streams-dataflow-output)
      <-- KSTREAM-MAP-0000000003
